{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set visualization styles\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'EthioMart/data/my_data.csv'  # Adjust to your data path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = data.drop(columns='target')  # Replace 'target' with your actual target column name\n",
    "y = data['target']\n",
    "\n",
    "# Optional: Scale features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC()\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y='F1 Score', data=results_df, palette='viridis')\n",
    "plt.title('Model Comparison: F1 Score')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Explanation of Sections\n",
    "\n",
    "1. **Import Libraries**: \n",
    "   - Import necessary libraries for data manipulation, visualization, and machine learning.\n",
    "\n",
    "2. **Load Data**: \n",
    "   - Load your dataset and display the first few rows.\n",
    "\n",
    "3. **Preprocess Data**: \n",
    "   - Prepare the data by splitting it into features and target variables. Optionally, scale the features and split the data into training and validation sets.\n",
    "\n",
    "4. **Train Models**: \n",
    "   - Initialize various machine learning models, fit them to the training data, and calculate evaluation metrics (accuracy, precision, recall, F1 score).\n",
    "\n",
    "5. **Compare Model Performance**: \n",
    "   - Store the results in a DataFrame, display the results, and visualize the F1 score for each model.\n",
    "\n",
    "6. **Conclusion**: \n",
    "   - Summarize the findings from the model comparison.\n",
    "\n",
    "### Usage\n",
    "\n",
    "- Save this content as `model_comparison.ipynb`.\n",
    "- Run the notebook using Jupyter Notebook or Jupyter Lab, ensuring the paths and column names align with your dataset.\n",
    "\n",
    "Feel free to add more models or evaluation metrics based on your specific requirements! If you need any further modifications or enhancements, just let me know!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
